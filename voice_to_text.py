# voice_to_text.py

import queue
import json
import pyaudio
import numpy as np
import threading
from vosk import Model, KaldiRecognizer

class VoiceToText:
    """
    This class allows you to continuously transcribe audio input into text.

    Attributes:
        model_path (str): The path to the Vosk model to be used for transcription.
        interval (int): The interval in seconds to check for audio energy.
        energy_threshold (int): The energy level that determines whether sound is present.
        max_threads (int): The maximum number of threads to use for processing audio.
    """

    def __init__(
            self,
            model_path: str,
            interval: int = 10,
            energy_threshold: int = 0,
            max_threads: int = 5,
        ) -> None:
        self.p = pyaudio.PyAudio()
        self.model = Model(model_path)
        self.interval = interval
        self.energy_threshold = energy_threshold
        self.max_threads = max_threads
        self.active_threads = 0
        self.stop_flag = threading.Event()
        self.transcriptions = queue.Queue()

    def get_audio_energy(self, data: bytes) -> float:
        """
        Returns the energy of the audio data.

        Args:
            data (bytes): The raw audio data to calculate energy from.

        Returns:
            energy (float): The energy of the audio data.
        """
        audio_data = np.frombuffer(data, dtype=np.int16)
        energy = np.sum(audio_data.astype(np.int32) ** 2) / len(audio_data)
        return energy

    def process_audio_data(self, data, semaphore) -> None:
        """
        Processes the given audio data by transcribing it into text.

        Args:
            data (bytes): The raw audio data to transcribe.
            semaphore (threading.Semaphore): The semaphore to release after processing.

        Returns:
            None

        Raises:
            ValueError: If transcription fails.
        """
        try:
            if self.rec.AcceptWaveform(data):
                result = json.loads(self.rec.Result())
                self.transcriptions.put(result)
        except Exception as e:
            raise ValueError(f"Transcription failed: {e}")
        finally:
            self.active_threads -= 1
            semaphore.release()

    def continuously_transcribe_audio(self) -> None:
        """
        Starts continuously transcribing audio.

        This method runs indefinitely until the stop flag is set.

        Args:
            None
        
        Returns:
            None

        Raises:
            KeyboardInterrupt: If the user interrupts the program.
        """
        stream = self.p.open(format=pyaudio.paInt16, channels=1, rate=16000, input=True, frames_per_buffer=8000)
        stream.start_stream()
        self.rec = KaldiRecognizer(self.model, 16000)

        buffer_duration = 8000 / 16000  # duration of each buffer in seconds
        buffers_per_interval = int(self.interval / buffer_duration)  # number of buffers per interval

        semaphore = threading.Semaphore(self.max_threads)

        try:
            while not self.stop_flag.is_set():
                data = b''
                has_talking = False
                for _ in range(buffers_per_interval):
                    buffer_data = stream.read(8000)
                    data += buffer_data

                    if self.get_audio_energy(buffer_data) > self.energy_threshold:
                        has_talking = True

                if has_talking:
                    semaphore.acquire()
                    self.active_threads += 1
                    thread = threading.Thread(target=self.process_audio_data, args=(data, semaphore))
                    thread.start()
                else:
                    print("No talking detected, skipping interval.")
        except KeyboardInterrupt:
            print("Stopped early")
        finally:
            for _ in range(self.active_threads):
                semaphore.release()
            stream.stop_stream()
            stream.close()
            self.p.terminate()

    def stop_recording(self) -> None:
        """
        Stops the audio transcription process.
        
        This method sets a stop flag that causes the `continuously_transcribe_audio` method to exit.

        Args:
            None

        Returns:
            None
        """
        self.stop_flag.set()

    def get_transcript(self) -> queue.Queue:
        """
        Gets the transcript

        Args:
            None

        Returns
            self.transcriptions (queue.Queue): a queue of all transcripts generated by the vosk model
        """
        return self.transcriptions
    
    def new_transcript(self) -> None:
        """
        Resets the transcript

        Args:
            None

        Returns:
            None
        """
        self.transcriptions = queue.Queue()